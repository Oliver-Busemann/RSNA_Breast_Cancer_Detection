{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68370f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from random import shuffle, seed\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import copy\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCELoss\n",
    "from tqdm.notebook import tqdm\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f17b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334a1e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c364cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'Preprocessed_Scans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d5fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b44445",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463bfe93",
   "metadata": {},
   "source": [
    "# Getting the CV-Setup done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd45ae",
   "metadata": {},
   "source": [
    "The Training data will be split into 5 folds where each fold should contain roughtly the same number of cancer cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b47846",
   "metadata": {},
   "source": [
    "For each patient the left and right breast can probably be placed in a different fold without causing any data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8236162",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function returns the image_ids for five folds with balanced cancer to non-cancer cases\n",
    "    To do this 5 lists for cancer scans & 5 lists for non-cancer scans are created\n",
    "    The scans are assinged by looping over all patient_ids\n",
    "    For each patient_id AND each breast, all scans are assined to the folder with the lowest amount of scan_ids\n",
    "    After that the scan_ids for cancer & non-cancer are added up to 5 folds each\n",
    "    The lengths are printed to make sure its balanced\n",
    "'''\n",
    "\n",
    "def get_folds_with_image_ids(DF):\n",
    "    \n",
    "    df = DF.copy()\n",
    "    \n",
    "    patient_ids = list(train_df['patient_id'].unique())  # all unique patient_ids\n",
    "    shuffle(patient_ids)\n",
    "    \n",
    "    # foldes to hold the image ids\n",
    "    cancer_fold_1, cancer_fold_2, cancer_fold_3, cancer_fold_4, cancer_fold_5 = [], [], [], [], []\n",
    "    no_cancer_fold_1, no_cancer_fold_2, no_cancer_fold_3, no_cancer_fold_4, no_cancer_fold_5 = [], [], [], [], []\n",
    "    \n",
    "    # list of folders\n",
    "    cancer_folders = [cancer_fold_1, cancer_fold_2, cancer_fold_3, cancer_fold_4, cancer_fold_5]\n",
    "    no_cancer_folders = [no_cancer_fold_1, no_cancer_fold_2, no_cancer_fold_3, no_cancer_fold_4, no_cancer_fold_5]\n",
    "    \n",
    "    # loop over all patient ids and assign them to a fold (each patient + side must be in a single fold)\n",
    "    for ID in tqdm(patient_ids):\n",
    "        for side in ['L', 'R']:\n",
    "            filt = (df['patient_id'] == ID) & (df['laterality'] == side)  # boolean df as filter\n",
    "            \n",
    "            # df only with the current patient id & one breast\n",
    "            current_df = df[filt]\n",
    "            \n",
    "            # image ids which should be assigned to one fold\n",
    "            values_to_assign = current_df['image_id'].values\n",
    "            \n",
    "            # array of cancer values from the selected df\n",
    "            cancer_value = current_df['cancer'].unique()\n",
    "            \n",
    "            # should only contain one value!\n",
    "            if len(cancer_value) > 1:\n",
    "                print('\\n\\n\\nERROR: GOT DIFFERENT CANCER VALUES!\\n\\n\\n')\n",
    "            else:\n",
    "                cancer_value = cancer_value[0]\n",
    "            \n",
    "            # the image ids should be assigned to the folder with the least values\n",
    "            \n",
    "            if cancer_value == 0:  # add it to one of no cancer folders...\n",
    "                len_folders = [len(folder) for folder in no_cancer_folders]\n",
    "                folder = np.array(len_folders).argmin()  # ...to the one with the least values in it\n",
    "                for image_id in values_to_assign:\n",
    "                    no_cancer_folders[folder].append(image_id)\n",
    "                    \n",
    "            # same with cancer_values\n",
    "            elif cancer_value == 1:\n",
    "                len_folders = [len(folder) for folder in cancer_folders]\n",
    "                folder = np.array(len_folders).argmin()  # the one with the least values\n",
    "                for image_id in values_to_assign:\n",
    "                    cancer_folders[folder].append(image_id)\n",
    "            \n",
    "    # check if the folders are balanced\n",
    "    len_cancer_folders = [len(folder) for folder in cancer_folders]\n",
    "    len_no_cancer_folders = [len(folder) for folder in no_cancer_folders]\n",
    "    print(f'Length of cancer folders: {len_cancer_folders}')\n",
    "    print(f'Length of non cancer folders: {len_no_cancer_folders}\\n')\n",
    "\n",
    "    # check if the values got assigned correct\n",
    "    counted_cancer_cases = sum([len(folder) for folder in cancer_folders])\n",
    "    number_cancer_cases = len(df[df['cancer'] == 1])\n",
    "    print(f'Number of cancer cases in total: {number_cancer_cases}')\n",
    "    print(f'Number of cancer cases in cancer folders: {counted_cancer_cases}\\n')\n",
    "\n",
    "    counted_no_cancer_cases = sum([len(folder) for folder in no_cancer_folders])\n",
    "    number_no_cancer_cases = len(df[df['cancer'] == 0])\n",
    "    print(f'Number of non cancer cases in total: {number_no_cancer_cases}')\n",
    "    print(f'Number of non cancer cases in non cancer folders: {counted_no_cancer_cases}\\n')\n",
    "\n",
    "    # add them up to five folds & shuffle them again\n",
    "    fold_1, fold_2, fold_3, fold_4, fold_5 = [cancer + no_cancer for cancer, no_cancer in\n",
    "                                              zip(cancer_folders, no_cancer_folders)]\n",
    "    [shuffle(fold) for fold in [fold_1, fold_2, fold_3, fold_4, fold_5]]\n",
    "\n",
    "    # print final length\n",
    "    print(f'Final Length of Folds: {[len(fold) for fold in [fold_1, fold_2, fold_3, fold_4, fold_5]]}')\n",
    "            \n",
    "    return fold_1, fold_2, fold_3, fold_4, fold_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6d5f437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5ea0d2585f496fa14b943d0394c71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of cancer folders: [234, 232, 230, 232, 230]\n",
      "Length of non cancer folders: [10711, 10709, 10709, 10710, 10709]\n",
      "\n",
      "Number of cancer cases in total: 1158\n",
      "Number of cancer cases in cancer folders: 1158\n",
      "\n",
      "Number of non cancer cases in total: 53548\n",
      "Number of non cancer cases in non cancer folders: 53548\n",
      "\n",
      "Final Length of Folds: [10945, 10941, 10939, 10942, 10939]\n",
      "CPU times: user 53.2 s, sys: 52.4 ms, total: 53.2 s\n",
      "Wall time: 53.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fold_1, fold_2, fold_3, fold_4, fold_5 = get_folds_with_image_ids(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc282b0",
   "metadata": {},
   "source": [
    "#### These 5 folds will be used to create 5 training & 5 validation folds (allways with one hold out valid fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ccea3b",
   "metadata": {},
   "source": [
    "#### So basically 4 folds will be added up for training & the last one is the validation folder (5 fold cross validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da0de9",
   "metadata": {},
   "source": [
    "## Augmentations based on paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72dae9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' For image augmentation; Used the recommended ones from Page 5 in paper:\n",
    "    Abdelhafiz, D., Bi, J., Ammar, R., Yang, C., & Nabavi, S. (2020). \n",
    "    Convolutional neural network for automated mass segmentation in mammography. BMC bioinformatics, 21(1), 1-19.\n",
    "'''\n",
    "\n",
    "augmentations = transforms.Compose([\n",
    "    transforms.RandomRotation(10),  # rotate the image by -10 to +10 degree\n",
    "    transforms.RandomHorizontalFlip(),  # flip it every 2nd time horizontally\n",
    "    transforms.RandomVerticalFlip(),  # same vertically\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # shift 10 % left/right or up/down\n",
    "    transforms.RandomResizedCrop(size=(512, 512), scale=(0.8, 1.2))  # zoom in/out by 20%\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081d3dc",
   "metadata": {},
   "source": [
    "## Pipeline for additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed40f324",
   "metadata": {},
   "source": [
    "This preprocessing pipeline will be used for the additional featured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4482450",
   "metadata": {},
   "source": [
    "Not only the preprocessed scans will be used but also the view, age, implant and machine_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6901c45a",
   "metadata": {},
   "source": [
    "Missing values need to be handled and they need to be scaled / encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6ae14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = ['age']  # numeric value\n",
    "cat_attribs = ['view', 'implant', 'machine_id']  # categorical values (implant for simplicitly too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9a1d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('Imputer_Median_Num', SimpleImputer(strategy='median')),  # fill Na with median value\n",
    "    ('Standardize_Num', StandardScaler())  # scale age to mean 0 and std 1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d4a4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    ('Imputer_Median_Cat', SimpleImputer(strategy='most_frequent')),  # fill Na with most frequent\n",
    "    ('OneHot', OneHotEncoder(sparse=False))  # create one-hot array and dont return sparse matrix\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b08f01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cat_pipeline = ColumnTransformer([\n",
    "    ('num_pipeline', num_pipeline, num_attribs),\n",
    "    ('cat_pipeline', cat_pipeline, cat_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c88a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_fitting = train_df[['age', 'view', 'implant', 'machine_id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae9048e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Imputer_Median_Num&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;Standardize_Num&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;age&#x27;]),\n",
       "                                (&#x27;cat_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Imputer_Median_Cat&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;OneHot&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False))]),\n",
       "                                 [&#x27;view&#x27;, &#x27;implant&#x27;, &#x27;machine_id&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Imputer_Median_Num&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;Standardize_Num&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;age&#x27;]),\n",
       "                                (&#x27;cat_pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Imputer_Median_Cat&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;OneHot&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False))]),\n",
       "                                 [&#x27;view&#x27;, &#x27;implant&#x27;, &#x27;machine_id&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_pipeline</label><div class=\"sk-toggleable__content\"><pre>[&#x27;view&#x27;, &#x27;implant&#x27;, &#x27;machine_id&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num_pipeline',\n",
       "                                 Pipeline(steps=[('Imputer_Median_Num',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('Standardize_Num',\n",
       "                                                  StandardScaler())]),\n",
       "                                 ['age']),\n",
       "                                ('cat_pipeline',\n",
       "                                 Pipeline(steps=[('Imputer_Median_Cat',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('OneHot',\n",
       "                                                  OneHotEncoder(sparse=False))]),\n",
       "                                 ['view', 'implant', 'machine_id'])])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cat_pipeline.fit(df_for_fitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54066630",
   "metadata": {},
   "source": [
    "See output (example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efe3650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_out = num_cat_pipeline.transform(df_for_fitting.iloc[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f93121dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24441783,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.24441783,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.24441783,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.24441783,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.35275163,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd59b819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 19)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad13e25",
   "metadata": {},
   "source": [
    "So 19 additional features will be added together with the output of the pretrained-network with the scans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30303dfa",
   "metadata": {},
   "source": [
    "## Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd56ea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Each Dataset will be initialized with the image ids of the corresponding fold that are defined laster\n",
    "    The Train-Dataframe will be filtered based on the image_ids of the fold\n",
    "    PROBLEM: The filtered Dataframe does not have the same order as the assined image_ids\n",
    "    -> It needs to be sorted by the image_ids\n",
    "    Each Index return the preprocessed and augmented scan from the last notebook as well as the additional featured\n",
    "    The features are also preprocessed based on the pipeline above\n",
    "'''\n",
    "\n",
    "\n",
    "class Data(Dataset):\n",
    "    \n",
    "    # same initialization\n",
    "    def __init__(self, fold_image_ids, DF, pipe, transform=None):\n",
    "        self.df = DF.copy()\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.pipe = pipe\n",
    "        \n",
    "        self.image_ids = copy.deepcopy(fold_image_ids)  # dont shuffle original\n",
    "        shuffle(self.image_ids)  # shuffle new image ids\n",
    "        \n",
    "        self.df_filtered = self.df[self.df['image_id'].isin(self.image_ids)]  # get df with initialized image_ids\n",
    "        \n",
    "        # Problem: The new dataframe should be sorted with the new image_ids to get the correct other values\n",
    "        self.df_sorted = self.df_filtered.iloc[np.argsort([self.image_ids.index(i) for i in \n",
    "                                                           self.df_filtered['image_id']])]\n",
    "        \n",
    "        # get the cancer value for each image id\n",
    "        self.targets = list(self.df_sorted['cancer'].values)\n",
    "        \n",
    "        # make df for pipeline\n",
    "        self.df_pipe = self.df_sorted[['age', 'view', 'implant', 'machine_id']].copy()\n",
    "        self.encoded = self.pipe.transform(self.df_pipe)  # these ancoded values can be grabed by index in getitem\n",
    "        \n",
    "        # also get the corresponding patient_ids for correct assignment below\n",
    "        self.patient_ids = list(self.df_sorted['patient_id'].values)\n",
    "                                              \n",
    "        self.n_samples = len(self.image_ids)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # get the correct scan of the preprocessed data\n",
    "        folder = train_folder\n",
    "        \n",
    "        patient_id = str(self.patient_ids[index])\n",
    "        image_id = str(self.image_ids[index])\n",
    "        \n",
    "        file_name = f'{patient_id}_{image_id}.pickle'  # new file name with new type\n",
    "        \n",
    "        path_img = os.path.join(folder, file_name)  # path to each image id\n",
    "        \n",
    "        with open(path_img, 'rb') as f:\n",
    "            X = pickle.load(f)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        \n",
    "        # to feed the grayscaled tensor into a pretrained rgb-model repeat the tensor 3 times in dim 0\n",
    "        X = X.repeat(3, 1, 1)\n",
    "        \n",
    "        y = torch.tensor(self.targets[index]).type(torch.float32)\n",
    "        \n",
    "        add_features = torch.Tensor(self.encoded[index]).type(torch.float32)\n",
    "        \n",
    "        \n",
    "        return (X, add_features), y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebbab76",
   "metadata": {},
   "source": [
    "## Class weights for upsampling cancer cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c058707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(DF):\n",
    "    df = DF.copy()\n",
    "    \n",
    "    num_cancer_cases = len(df[df['cancer'] == 1])\n",
    "    num_no_cancer_cases = len(df[df['cancer'] == 0])\n",
    "    \n",
    "    # the class weights just need to have a correct relative size\n",
    "    # class weight for no cancer cases is set as 1 -> cancer cases weight is the number they appear less\n",
    "    no_cancer_weight = 1\n",
    "    cancer_weight = round(num_no_cancer_cases / num_cancer_cases, 2)\n",
    "    \n",
    "    print(f'Weights: No Cancer: {no_cancer_weight}; Cancer: {cancer_weight}')\n",
    "    \n",
    "    return [no_cancer_weight, cancer_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c46633b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: No Cancer: 1; Cancer: 46.24\n"
     ]
    }
   ],
   "source": [
    "class_weights = get_class_weights(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a623d02",
   "metadata": {},
   "source": [
    "# Building the model (Combining EfficientNet with a Custom Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18ff2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = timm.create_model('tf_efficientnetv2_xl_in21k', pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77bf7c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pretrained model weights untrainable\n",
    "for param in model_1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d60568f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "EfficientNet                                  [2, 21843]                --\n",
       "├─Conv2dSame: 1-1                             [2, 32, 256, 256]         (864)\n",
       "├─BatchNormAct2d: 1-2                         [2, 32, 256, 256]         64\n",
       "│    └─Identity: 2-1                          [2, 32, 256, 256]         --\n",
       "│    └─SiLU: 2-2                              [2, 32, 256, 256]         --\n",
       "├─Sequential: 1-3                             [2, 640, 16, 16]          --\n",
       "│    └─Sequential: 2-3                        [2, 32, 256, 256]         --\n",
       "│    │    └─ConvBnAct: 3-1                    [2, 32, 256, 256]         (9,280)\n",
       "│    │    └─ConvBnAct: 3-2                    [2, 32, 256, 256]         (9,280)\n",
       "│    │    └─ConvBnAct: 3-3                    [2, 32, 256, 256]         (9,280)\n",
       "│    │    └─ConvBnAct: 3-4                    [2, 32, 256, 256]         (9,280)\n",
       "│    └─Sequential: 2-4                        [2, 64, 128, 128]         --\n",
       "│    │    └─EdgeResidual: 3-5                 [2, 64, 128, 128]         (45,440)\n",
       "│    │    └─EdgeResidual: 3-6                 [2, 64, 128, 128]         (164,480)\n",
       "│    │    └─EdgeResidual: 3-7                 [2, 64, 128, 128]         (164,480)\n",
       "│    │    └─EdgeResidual: 3-8                 [2, 64, 128, 128]         (164,480)\n",
       "│    │    └─EdgeResidual: 3-9                 [2, 64, 128, 128]         (164,480)\n",
       "│    │    └─EdgeResidual: 3-10                [2, 64, 128, 128]         (164,480)\n",
       "│    │    └─EdgeResidual: 3-11                [2, 64, 128, 128]         (164,480)\n",
       "│    │    └─EdgeResidual: 3-12                [2, 64, 128, 128]         (164,480)\n",
       "│    └─Sequential: 2-5                        [2, 96, 64, 64]           --\n",
       "│    │    └─EdgeResidual: 3-13                [2, 96, 64, 64]           (172,736)\n",
       "│    │    └─EdgeResidual: 3-14                [2, 96, 64, 64]           (369,600)\n",
       "│    │    └─EdgeResidual: 3-15                [2, 96, 64, 64]           (369,600)\n",
       "│    │    └─EdgeResidual: 3-16                [2, 96, 64, 64]           (369,600)\n",
       "│    │    └─EdgeResidual: 3-17                [2, 96, 64, 64]           (369,600)\n",
       "│    │    └─EdgeResidual: 3-18                [2, 96, 64, 64]           (369,600)\n",
       "│    │    └─EdgeResidual: 3-19                [2, 96, 64, 64]           (369,600)\n",
       "│    │    └─EdgeResidual: 3-20                [2, 96, 64, 64]           (369,600)\n",
       "│    └─Sequential: 2-6                        [2, 192, 32, 32]          --\n",
       "│    │    └─InvertedResidual: 3-21            [2, 192, 32, 32]          (134,808)\n",
       "│    │    └─InvertedResidual: 3-22            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-23            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-24            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-25            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-26            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-27            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-28            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-29            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-30            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-31            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-32            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-33            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-34            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-35            [2, 192, 32, 32]          (379,824)\n",
       "│    │    └─InvertedResidual: 3-36            [2, 192, 32, 32]          (379,824)\n",
       "│    └─Sequential: 2-7                        [2, 256, 32, 32]          --\n",
       "│    │    └─InvertedResidual: 3-37            [2, 256, 32, 32]          (643,376)\n",
       "│    │    └─InvertedResidual: 3-38            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-39            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-40            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-41            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-42            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-43            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-44            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-45            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-46            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-47            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-48            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-49            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-50            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-51            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-52            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-53            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-54            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-55            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-56            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-57            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-58            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-59            [2, 256, 32, 32]          (1,005,120)\n",
       "│    │    └─InvertedResidual: 3-60            [2, 256, 32, 32]          (1,005,120)\n",
       "│    └─Sequential: 2-8                        [2, 512, 16, 16]          --\n",
       "│    │    └─InvertedResidual: 3-61            [2, 512, 16, 16]          (1,398,848)\n",
       "│    │    └─InvertedResidual: 3-62            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-63            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-64            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-65            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-66            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-67            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-68            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-69            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-70            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-71            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-72            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-73            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-74            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-75            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-76            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-77            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-78            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-79            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-80            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-81            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-82            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-83            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-84            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-85            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-86            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-87            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-88            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-89            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-90            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-91            [2, 512, 16, 16]          (3,976,320)\n",
       "│    │    └─InvertedResidual: 3-92            [2, 512, 16, 16]          (3,976,320)\n",
       "│    └─Sequential: 2-9                        [2, 640, 16, 16]          --\n",
       "│    │    └─InvertedResidual: 3-93            [2, 640, 16, 16]          (4,369,792)\n",
       "│    │    └─InvertedResidual: 3-94            [2, 640, 16, 16]          (6,199,200)\n",
       "│    │    └─InvertedResidual: 3-95            [2, 640, 16, 16]          (6,199,200)\n",
       "│    │    └─InvertedResidual: 3-96            [2, 640, 16, 16]          (6,199,200)\n",
       "│    │    └─InvertedResidual: 3-97            [2, 640, 16, 16]          (6,199,200)\n",
       "│    │    └─InvertedResidual: 3-98            [2, 640, 16, 16]          (6,199,200)\n",
       "│    │    └─InvertedResidual: 3-99            [2, 640, 16, 16]          (6,199,200)\n",
       "│    │    └─InvertedResidual: 3-100           [2, 640, 16, 16]          (6,199,200)\n",
       "├─Conv2d: 1-4                                 [2, 1280, 16, 16]         (819,200)\n",
       "├─BatchNormAct2d: 1-5                         [2, 1280, 16, 16]         2,560\n",
       "│    └─Identity: 2-10                         [2, 1280, 16, 16]         --\n",
       "│    └─SiLU: 2-11                             [2, 1280, 16, 16]         --\n",
       "├─SelectAdaptivePool2d: 1-6                   [2, 1280]                 --\n",
       "│    └─AdaptiveAvgPool2d: 2-12                [2, 1280, 1, 1]           --\n",
       "│    └─Flatten: 2-13                          [2, 1280]                 --\n",
       "├─Linear: 1-7                                 [2, 21843]                (27,980,883)\n",
       "===============================================================================================\n",
       "Total params: 234,819,691\n",
       "Trainable params: 0\n",
       "Non-trainable params: 234,819,691\n",
       "Total mult-adds (G): 186.76\n",
       "===============================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 3957.45\n",
       "Params size (MB): 936.17\n",
       "Estimated Total Size (MB): 4899.91\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_1, input_data=torch.randn((2, 3, 512, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a67fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity layer to replace the Classification layer in EfficientNet\n",
    "\n",
    "class Identity(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e98dd192",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8cb9dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.classifier = identity  # puts it on gpu by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c3774",
   "metadata": {},
   "source": [
    "Now an additional model must be created that takes as input the EffNet output as well as the additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8b11f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second model that takes as inout the efficientnet output and the additional featured from the dataset\n",
    "\n",
    "class Second_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.fc_1 = nn.Linear(1280, 32)\n",
    "        self.bn_1 = nn.BatchNorm1d(32)\n",
    "        self.act_1 = nn.ReLU()\n",
    "        self.drop_1 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.fc_2 = nn.Linear(51, 8)  # 51 with added features (32 + 19add_features)\n",
    "        self.bn_2 = nn.BatchNorm1d(8)\n",
    "        self.act_2 = nn.ReLU()\n",
    "        self.drop_2 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.fc_3 = nn.Linear(8, 1)\n",
    "        self.out = nn.Sigmoid()\n",
    "    \n",
    "    # add view, age, implant and machine_id as features\n",
    "    # view, implants and machine id will be one hot encoded (6, 2, 10 values)\n",
    "    # age single scalar  -> 19 additional values added at \n",
    "    def forward(self, x, add_features):\n",
    "\n",
    "        x = self.fc_1(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = self.act_1(x)\n",
    "        x = self.drop_1(x)\n",
    "\n",
    "        x = torch.cat((x, add_features), dim=1)\n",
    "\n",
    "        x = self.fc_2(x)\n",
    "        x = self.bn_2(x)\n",
    "        x = self.act_2(x)\n",
    "        x = self.drop_2(x)\n",
    "        \n",
    "        x = self.fc_3(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ab50dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Second_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc713839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Second_Model(\n",
       "  (fc_1): Linear(in_features=1280, out_features=32, bias=True)\n",
       "  (bn_1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act_1): ReLU()\n",
       "  (drop_1): Dropout(p=0.25, inplace=False)\n",
       "  (fc_2): Linear(in_features=51, out_features=8, bias=True)\n",
       "  (bn_2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act_2): ReLU()\n",
       "  (drop_2): Dropout(p=0.25, inplace=False)\n",
       "  (fc_3): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39035bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model that consists of model_1 and model_2\n",
    "\n",
    "class Combined_Model(torch.nn.Module):\n",
    "    def __init__(self, MODEL_1, MODEL_2):\n",
    "        super().__init__()\n",
    "        self.model_1 = model_1\n",
    "        self.model_2 = model_2\n",
    "        \n",
    "    def forward(self, x, add_features):\n",
    "        \n",
    "        x = self.model_1(x)\n",
    "        \n",
    "        x = model_2(x, add_features)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a081792",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_model = Combined_Model(MODEL_1=model_1, MODEL_2=model_2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b46fad4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "Combined_Model                                     [2, 1]                    --\n",
       "├─EfficientNet: 1-1                                [2, 1280]                 --\n",
       "│    └─Conv2dSame: 2-1                             [2, 32, 256, 256]         (864)\n",
       "│    └─BatchNormAct2d: 2-2                         [2, 32, 256, 256]         64\n",
       "│    │    └─Identity: 3-1                          [2, 32, 256, 256]         --\n",
       "│    │    └─SiLU: 3-2                              [2, 32, 256, 256]         --\n",
       "│    └─Sequential: 2-3                             [2, 640, 16, 16]          --\n",
       "│    │    └─Sequential: 3-3                        [2, 32, 256, 256]         (37,120)\n",
       "│    │    └─Sequential: 3-4                        [2, 64, 128, 128]         (1,196,800)\n",
       "│    │    └─Sequential: 3-5                        [2, 96, 64, 64]           (2,759,936)\n",
       "│    │    └─Sequential: 3-6                        [2, 192, 32, 32]          (5,832,168)\n",
       "│    │    └─Sequential: 3-7                        [2, 256, 32, 32]          (23,761,136)\n",
       "│    │    └─Sequential: 3-8                        [2, 512, 16, 16]          (124,664,768)\n",
       "│    │    └─Sequential: 3-9                        [2, 640, 16, 16]          (47,764,192)\n",
       "│    └─Conv2d: 2-4                                 [2, 1280, 16, 16]         (819,200)\n",
       "│    └─BatchNormAct2d: 2-5                         [2, 1280, 16, 16]         2,560\n",
       "│    │    └─Identity: 3-10                         [2, 1280, 16, 16]         --\n",
       "│    │    └─SiLU: 3-11                             [2, 1280, 16, 16]         --\n",
       "│    └─SelectAdaptivePool2d: 2-6                   [2, 1280]                 --\n",
       "│    │    └─AdaptiveAvgPool2d: 3-12                [2, 1280, 1, 1]           --\n",
       "│    │    └─Flatten: 3-13                          [2, 1280]                 --\n",
       "│    └─Identity: 2-7                               [2, 1280]                 --\n",
       "├─Second_Model: 1-2                                [2, 1]                    --\n",
       "│    └─Linear: 2-8                                 [2, 32]                   40,992\n",
       "│    └─BatchNorm1d: 2-9                            [2, 32]                   64\n",
       "│    └─ReLU: 2-10                                  [2, 32]                   --\n",
       "│    └─Dropout: 2-11                               [2, 32]                   --\n",
       "│    └─Linear: 2-12                                [2, 8]                    416\n",
       "│    └─BatchNorm1d: 2-13                           [2, 8]                    16\n",
       "│    └─ReLU: 2-14                                  [2, 8]                    --\n",
       "│    └─Dropout: 2-15                               [2, 8]                    --\n",
       "│    └─Linear: 2-16                                [2, 1]                    9\n",
       "│    └─Sigmoid: 2-17                               [2, 1]                    --\n",
       "====================================================================================================\n",
       "Total params: 206,880,305\n",
       "Trainable params: 41,497\n",
       "Non-trainable params: 206,838,808\n",
       "Total mult-adds (G): 186.70\n",
       "====================================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 3957.10\n",
       "Params size (MB): 824.41\n",
       "Estimated Total Size (MB): 4787.81\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(comb_model, input_data=(torch.randn(2, 3, 512, 512).to(device), torch.randn(2, 19).to(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f0a2d",
   "metadata": {},
   "source": [
    "### Save initial (random) weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89a5c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = 'MODEL_INITIAL_WEIGHTS.pth'\n",
    "torch.save(comb_model.state_dict(), initial_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf31f12",
   "metadata": {},
   "source": [
    "Saved model weights will be used to start every cv-folder with a newly initialized model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51032083",
   "metadata": {},
   "source": [
    "# Training and validation functions (loss and pF1-Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a80a3abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function for predicting a batch, calculating the loss,\n",
    "   calculate the gradients & adjust weights'''\n",
    "\n",
    "def train_batch(model, loss, optimizer, X, add_features, y):\n",
    "    model.train()  # set model to training mode\n",
    "\n",
    "    pred = model(X, add_features)  # prediction for current batch features\n",
    "    \n",
    "    pred = pred.clip(0.05, 0.95)  # set a threshold\n",
    "    \n",
    "    pred = pred.squeeze()  # remove batch size dim\n",
    "    \n",
    "    weight_indices = y.int()  # make y the weight indices (need to be int not float)\n",
    "    \n",
    "    weights = torch.Tensor([class_weights[i] for i in weight_indices]).to(device)  # loss weight\n",
    "    \n",
    "    loss.weight = weights  # assign it\n",
    "    \n",
    "    batch_loss = loss(pred, y)  # calculate loss\n",
    "    \n",
    "    batch_loss.backward()  # backpropagate\n",
    "    \n",
    "    optimizer.step()  # adjust trainable weights\n",
    "    \n",
    "    optimizer.zero_grad()  # remove gradients for next batch\n",
    "    \n",
    "    return batch_loss.item()  # return loss value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c583050",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function for calculating validation loss without adjusting the weights'''\n",
    "\n",
    "@torch.no_grad()\n",
    "def calculate_val_loss(model, loss, X, add_features, y):\n",
    "    model.eval()  # evaluation mode\n",
    "    \n",
    "    pred = model(X, add_features)\n",
    "    \n",
    "    pred = pred.squeeze()\n",
    "    \n",
    "    pred = pred.clip(0.05, 0.95)\n",
    "    \n",
    "    weight_indices = y.int()\n",
    "    \n",
    "    weights = torch.Tensor([class_weights[i] for i in weight_indices]).to(device)\n",
    "    \n",
    "    loss.weight = weights\n",
    "    \n",
    "    batch_loss = loss(pred, y)\n",
    "    \n",
    "    return batch_loss.item()  # just return the loss for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f14b696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Takes as input a batch (tensor) and returns the pF1 score'''\n",
    "\n",
    "def pF1(labels, preds, beta=1):\n",
    "    preds = preds.clip(0, 1)  # make sure predictions are between 0 and 1\n",
    "    y_true_count = labels.sum()  # number of true positive is the sum of labels (since false is 0 - no cancer)\n",
    "    ctp = preds[labels==1].sum()  # count of true positive scores (sum the values)\n",
    "    cfp = preds[labels==0].sum()  # count of false positives (sum where predictions should be 0)\n",
    "    beta_squared = beta * beta\n",
    "    # calculate precision & recall for the pF1 score\n",
    "    c_precision = ctp / (ctp + cfp + 1e-4)  # add epsilon so there is no zero division error\n",
    "    c_recall = ctp / (y_true_count + 1e-4)\n",
    "    if (c_precision > 0 and c_recall > 0):\n",
    "        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + 1e-4)\n",
    "        return float(result.cpu())  # should be a python float like loss.item()\n",
    "    else:\n",
    "        return 0.0  # this is prob. the reason why score with a batch_size of 32 is very low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11d6e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculate the pF1 score for a single batch without weight adjustments'''\n",
    "\n",
    "@torch.no_grad()\n",
    "def calculate_pF1(model, X, add_features, y):\n",
    "    model.eval()    \n",
    "    \n",
    "    pred = model(X, add_features)\n",
    "    \n",
    "    pred = pred.squeeze()\n",
    "    \n",
    "    pred = pred.clip(0.05, 0.95)\n",
    "    \n",
    "    pF1_score = pF1(labels=y, preds=pred)\n",
    "    \n",
    "    return pF1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7abd5d",
   "metadata": {},
   "source": [
    "# Create the 5 training- & validation-folds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a86077",
   "metadata": {},
   "source": [
    "#### Each folds once is the validation fold; rest is for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9f26688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1af3729fe6489894eabee655a69bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 35.8 ms, total: 1min 40s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''First set up the CV, so that each fold once is the validation folder and the rest of the folds is used for train\n",
    "   For that create the datasets and dataloaders for each fold, otherwise they need to be created \n",
    "   (epochs * fold) times which takes quite some time (~100s * epochs)\n",
    "'''\n",
    "folds = [fold_1, fold_2, fold_3, fold_4, fold_5]  # all 5 folds created above\n",
    "\n",
    "# variable names for assignment\n",
    "train_ds_names = ['train_ds_1', 'train_ds_2', 'train_ds_3', 'train_ds_4', 'train_ds_5']\n",
    "valid_ds_names = ['valid_ds_1', 'valid_ds_2', 'valid_ds_3', 'valid_ds_4', 'valid_ds_5']\n",
    "\n",
    "#fold ==  5, 4, 3, 2, 1 for current val fold index\n",
    "for fold, tr_ds, val_ds in tqdm(zip(range(len(folds), 0, -1), train_ds_names, valid_ds_names)):\n",
    "    \n",
    "    val_fold_index = fold - 1  # index of current val fold\n",
    "    train_fold_indices = list(range(0, len(folds)))  # all fold indices\n",
    "    train_fold_indices.remove(val_fold_index)  # all training folds (current val fold excluded)\n",
    "\n",
    "    train_image_ids = []\n",
    "    for index in train_fold_indices:\n",
    "        train_image_ids += folds[index]  # add images ids of each train folds up\n",
    "\n",
    "    val_image_ids = folds[val_fold_index]\n",
    "\n",
    "    # create the datasets for the current folders & assign them to a global variable to keep them\n",
    "    globals()[tr_ds] = Data(fold_image_ids=train_image_ids, DF=train_df, transform=augmentations, pipe=num_cat_pipeline)\n",
    "    globals()[val_ds] = Data(fold_image_ids=val_image_ids, DF=train_df, pipe=num_cat_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45c5bf",
   "metadata": {},
   "source": [
    "## Check for each validation folder if any image_id is in the corresponding training folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac10a738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Image IDs is equal to all IDs: True (54706==54706)\n",
      "Training-Fold 0 contains 0 of valid image IDs\n",
      "\n",
      "Fold 1: Image IDs is equal to all IDs: True (54706==54706)\n",
      "Training-Fold 1 contains 0 of valid image IDs\n",
      "\n",
      "Fold 2: Image IDs is equal to all IDs: True (54706==54706)\n",
      "Training-Fold 2 contains 0 of valid image IDs\n",
      "\n",
      "Fold 3: Image IDs is equal to all IDs: True (54706==54706)\n",
      "Training-Fold 3 contains 0 of valid image IDs\n",
      "\n",
      "Fold 4: Image IDs is equal to all IDs: True (54706==54706)\n",
      "Training-Fold 4 contains 0 of valid image IDs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_datasets = [train_ds_1, train_ds_2, train_ds_3, train_ds_4, train_ds_5]\n",
    "valid_datasets = [valid_ds_1, valid_ds_2, valid_ds_3, valid_ds_4, valid_ds_5]\n",
    "\n",
    "max_len = len(train_df)\n",
    "\n",
    "for fold, train_ds, valid_ds in zip(range(len(train_datasets)), train_datasets, valid_datasets):\n",
    "    tr_image_ids = train_ds.image_ids\n",
    "    val_image_ids = valid_ds.image_ids\n",
    "    total_ids = len(tr_image_ids) + len(val_image_ids)\n",
    "    \n",
    "    print(f'Fold {fold}: Image IDs is equal to all IDs: {max_len == total_ids} ({max_len}=={total_ids})')\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for val_image_id in val_image_ids:\n",
    "        in_train = tr_image_ids.count(val_image_id)  # number of times val_image_id is in train_image_ids\n",
    "        counter += in_train\n",
    "        \n",
    "    print(f'Training-Fold {fold} contains {counter} of valid image IDs\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46468ec7",
   "metadata": {},
   "source": [
    "# Creating the DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0457b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9112241b0e477b8c12a8ee328e6059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_dl_names = ['train_dl_1', 'train_dl_2', 'train_dl_3', 'train_dl_4', 'train_dl_5']\n",
    "val_dl_names = ['valid_dl_1', 'valid_dl_2', 'valid_dl_3', 'valid_dl_4', 'valid_dl_5']\n",
    "\n",
    "for train_ds, valid_ds, train_dl, valid_dl in tqdm(zip(train_datasets, valid_datasets, tr_dl_names, val_dl_names)):\n",
    "        \n",
    "    globals()[train_dl] = DataLoader(train_ds, batch_size=32, num_workers=24, pin_memory=True, drop_last=True)\n",
    "                                     #, multiprocessing_context='spawn')\n",
    "    \n",
    "    globals()[valid_dl] = DataLoader(valid_ds, batch_size=32, num_workers=24, pin_memory=True, drop_last=True)\n",
    "                                    #, multiprocessing_context='spawn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6d377d",
   "metadata": {},
   "source": [
    "# Train 5 models with the dl & functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7057ee2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91044a15f09f450db72de86406747d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1/12 - Training\n",
      "Finished Epoch 1/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 1/12 - Loss_Validation\n",
      "Finished Epoch 1/12 - pF1_Validation\n",
      "Train: Loss: 1.3601753381629362, pF1: 0.04044706181704115\n",
      "Valid: Loss: 1.3957690509183664, pF1: 0.03964044351289131\n",
      "Finished Epoch 2/12 - Training\n",
      "Finished Epoch 2/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 2/12 - Loss_Validation\n",
      "Finished Epoch 2/12 - pF1_Validation\n",
      "Train: Loss: 1.3185216221132676, pF1: 0.04196262179929068\n",
      "Valid: Loss: 1.3917809044860325, pF1: 0.04133936843924945\n",
      "Finished Epoch 3/12 - Training\n",
      "Finished Epoch 3/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 3/12 - Loss_Validation\n",
      "Finished Epoch 3/12 - pF1_Validation\n",
      "Train: Loss: 1.3055803729132658, pF1: 0.04264525494837334\n",
      "Valid: Loss: 1.3743464168914952, pF1: 0.04141586230346753\n",
      "Finished Epoch 4/12 - Training\n",
      "Finished Epoch 4/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 4/12 - Loss_Validation\n",
      "Finished Epoch 4/12 - pF1_Validation\n",
      "Train: Loss: 1.2851011988099859, pF1: 0.04349369711454497\n",
      "Valid: Loss: 1.3897144343496417, pF1: 0.04154989914285822\n",
      "Finished Epoch 5/12 - Training\n",
      "Finished Epoch 5/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 5/12 - Loss_Validation\n",
      "Finished Epoch 5/12 - pF1_Validation\n",
      "Train: Loss: 1.27605337427756, pF1: 0.04477362718191965\n",
      "Valid: Loss: 1.4073051550695974, pF1: 0.04085527659500362\n",
      "Finished Epoch 6/12 - Training\n",
      "Finished Epoch 6/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 6/12 - Loss_Validation\n",
      "Finished Epoch 6/12 - pF1_Validation\n",
      "Train: Loss: 1.26760124497459, pF1: 0.04553891945665739\n",
      "Valid: Loss: 1.3887157516220798, pF1: 0.04104143028390591\n",
      "Finished Epoch 7/12 - Training\n",
      "Finished Epoch 7/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 7/12 - Loss_Validation\n",
      "Finished Epoch 7/12 - pF1_Validation\n",
      "Train: Loss: 1.2605958718318702, pF1: 0.046266575252954745\n",
      "Valid: Loss: 1.410134993078422, pF1: 0.04165743643696532\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Finished Epoch 8/12 - Training\n",
      "Finished Epoch 8/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 8/12 - Loss_Validation\n",
      "Finished Epoch 8/12 - pF1_Validation\n",
      "Train: Loss: 1.2509904463708008, pF1: 0.04622294148941195\n",
      "Valid: Loss: 1.3738272941706817, pF1: 0.04239228109302016\n",
      "Finished Epoch 9/12 - Training\n",
      "Finished Epoch 9/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 9/12 - Loss_Validation\n",
      "Finished Epoch 9/12 - pF1_Validation\n",
      "Train: Loss: 1.2527900471160598, pF1: 0.046685337597244005\n",
      "Valid: Loss: 1.412793295998727, pF1: 0.04216906032456724\n",
      "Finished Epoch 10/12 - Training\n",
      "Finished Epoch 10/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 10/12 - Loss_Validation\n",
      "Finished Epoch 10/12 - pF1_Validation\n",
      "Train: Loss: 1.2400568576302071, pF1: 0.04659500422914074\n",
      "Valid: Loss: 1.3468073688644118, pF1: 0.04299534610513587\n",
      "Finished Epoch 11/12 - Training\n",
      "Finished Epoch 11/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 11/12 - Loss_Validation\n",
      "Finished Epoch 11/12 - pF1_Validation\n",
      "Train: Loss: 1.2372245100090429, pF1: 0.04653922461849401\n",
      "Valid: Loss: 1.3744348000920763, pF1: 0.042688899307547254\n",
      "Finished Epoch 12/12 - Training\n",
      "Finished Epoch 12/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 12/12 - Loss_Validation\n",
      "Finished Epoch 12/12 - pF1_Validation\n",
      "Train: Loss: 1.2244655436726495, pF1: 0.04713167788613459\n",
      "Valid: Loss: 1.3605619270430982, pF1: 0.04304392658354294\n",
      "FOLD 2 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44cb9d54cc744d897c57d115ec637f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1/12 - Training\n",
      "Finished Epoch 1/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 1/12 - Loss_Validation\n",
      "Finished Epoch 1/12 - pF1_Validation\n",
      "Train: Loss: 1.3550841752507867, pF1: 0.04063786946519141\n",
      "Valid: Loss: 1.4531251772407912, pF1: 0.038833390634583416\n",
      "Finished Epoch 2/12 - Training\n",
      "Finished Epoch 2/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 2/12 - Loss_Validation\n",
      "Finished Epoch 2/12 - pF1_Validation\n",
      "Train: Loss: 1.329253738390414, pF1: 0.041482227932778955\n",
      "Valid: Loss: 1.4529013811143612, pF1: 0.039686706192966256\n",
      "Finished Epoch 3/12 - Training\n",
      "Finished Epoch 3/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 3/12 - Loss_Validation\n",
      "Finished Epoch 3/12 - pF1_Validation\n",
      "Train: Loss: 1.3043438749934255, pF1: 0.04226896345605849\n",
      "Valid: Loss: 1.4111802701201956, pF1: 0.041186393728845715\n",
      "Finished Epoch 4/12 - Training\n",
      "Finished Epoch 4/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 4/12 - Loss_Validation\n",
      "Finished Epoch 4/12 - pF1_Validation\n",
      "Train: Loss: 1.2937128416534402, pF1: 0.04280275479435986\n",
      "Valid: Loss: 1.399853315783386, pF1: 0.042301045441207996\n",
      "Finished Epoch 5/12 - Training\n",
      "Finished Epoch 5/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 5/12 - Loss_Validation\n",
      "Finished Epoch 5/12 - pF1_Validation\n",
      "Train: Loss: 1.2860819137087685, pF1: 0.04375159468749796\n",
      "Valid: Loss: 1.4336492562573677, pF1: 0.041606446808679275\n",
      "Finished Epoch 6/12 - Training\n",
      "Finished Epoch 6/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 6/12 - Loss_Validation\n",
      "Finished Epoch 6/12 - pF1_Validation\n",
      "Train: Loss: 1.2761645004011544, pF1: 0.044437025920654856\n",
      "Valid: Loss: 1.3822720347961024, pF1: 0.042899477926473466\n",
      "Finished Epoch 7/12 - Training\n",
      "Finished Epoch 7/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 7/12 - Loss_Validation\n",
      "Finished Epoch 7/12 - pF1_Validation\n",
      "Train: Loss: 1.268896151173263, pF1: 0.04479653739091758\n",
      "Valid: Loss: 1.3739496668762476, pF1: 0.043221568654610874\n",
      "Finished Epoch 8/12 - Training\n",
      "Finished Epoch 8/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 8/12 - Loss_Validation\n",
      "Finished Epoch 8/12 - pF1_Validation\n",
      "Train: Loss: 1.2546029384326307, pF1: 0.04548860996983395\n",
      "Valid: Loss: 1.4289102986061677, pF1: 0.042495592389408705\n",
      "Finished Epoch 9/12 - Training\n",
      "Finished Epoch 9/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 9/12 - Loss_Validation\n",
      "Finished Epoch 9/12 - pF1_Validation\n",
      "Train: Loss: 1.2499975769643636, pF1: 0.04582183042523433\n",
      "Valid: Loss: 1.376224310691755, pF1: 0.0440170943663289\n",
      "Finished Epoch 10/12 - Training\n",
      "Finished Epoch 10/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 10/12 - Loss_Validation\n",
      "Finished Epoch 10/12 - pF1_Validation\n",
      "Train: Loss: 1.2534401357915161, pF1: 0.04620548270045948\n",
      "Valid: Loss: 1.399358507300402, pF1: 0.0447123218368728\n",
      "Finished Epoch 11/12 - Training\n",
      "Finished Epoch 11/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 11/12 - Loss_Validation\n",
      "Finished Epoch 11/12 - pF1_Validation\n",
      "Train: Loss: 1.2420500852194858, pF1: 0.046693206760669896\n",
      "Valid: Loss: 1.343636672954755, pF1: 0.04630754010948487\n",
      "Finished Epoch 12/12 - Training\n",
      "Finished Epoch 12/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 12/12 - Loss_Validation\n",
      "Finished Epoch 12/12 - pF1_Validation\n",
      "Train: Loss: 1.2419328640304348, pF1: 0.047597134660591525\n",
      "Valid: Loss: 1.3758532580567244, pF1: 0.04487361138566367\n",
      "FOLD 3 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0f71933cbd4e6191663e8a9a727738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1/12 - Training\n",
      "Finished Epoch 1/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 1/12 - Loss_Validation\n",
      "Finished Epoch 1/12 - pF1_Validation\n",
      "Train: Loss: 1.3630436853762518, pF1: 0.04023857612637006\n",
      "Valid: Loss: 1.3712425349045358, pF1: 0.04007411805798144\n",
      "Finished Epoch 2/12 - Training\n",
      "Finished Epoch 2/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 2/12 - Loss_Validation\n",
      "Finished Epoch 2/12 - pF1_Validation\n",
      "Train: Loss: 1.3290031770763384, pF1: 0.04142889220215756\n",
      "Valid: Loss: 1.3654463712420981, pF1: 0.04021836815216193\n",
      "Finished Epoch 3/12 - Training\n",
      "Finished Epoch 3/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 3/12 - Loss_Validation\n",
      "Finished Epoch 3/12 - pF1_Validation\n",
      "Train: Loss: 1.3053233486592726, pF1: 0.04232450900156522\n",
      "Valid: Loss: 1.3768360846378236, pF1: 0.04073533113319372\n",
      "Finished Epoch 4/12 - Training\n",
      "Finished Epoch 4/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 4/12 - Loss_Validation\n",
      "Finished Epoch 4/12 - pF1_Validation\n",
      "Train: Loss: 1.286768279724428, pF1: 0.0429070875881173\n",
      "Valid: Loss: 1.3693177006985784, pF1: 0.040935471644379266\n",
      "Finished Epoch 5/12 - Training\n",
      "Finished Epoch 5/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 5/12 - Loss_Validation\n",
      "Finished Epoch 5/12 - pF1_Validation\n",
      "Train: Loss: 1.2846863373579906, pF1: 0.04435099946197338\n",
      "Valid: Loss: 1.3602220087456913, pF1: 0.0420186733034961\n",
      "Finished Epoch 6/12 - Training\n",
      "Finished Epoch 6/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 6/12 - Loss_Validation\n",
      "Finished Epoch 6/12 - pF1_Validation\n",
      "Train: Loss: 1.268807178836019, pF1: 0.04438780099780305\n",
      "Valid: Loss: 1.379512066715274, pF1: 0.039905796721960006\n",
      "Finished Epoch 7/12 - Training\n",
      "Finished Epoch 7/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 7/12 - Loss_Validation\n",
      "Finished Epoch 7/12 - pF1_Validation\n",
      "Train: Loss: 1.2498907029585151, pF1: 0.04548920204845239\n",
      "Valid: Loss: 1.348628688592715, pF1: 0.04345437968723323\n",
      "Finished Epoch 8/12 - Training\n",
      "Finished Epoch 8/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 8/12 - Loss_Validation\n",
      "Finished Epoch 8/12 - pF1_Validation\n",
      "Train: Loss: 1.2432114960681633, pF1: 0.04610248709481752\n",
      "Valid: Loss: 1.3359388415414917, pF1: 0.043299548809971014\n",
      "Finished Epoch 9/12 - Training\n",
      "Finished Epoch 9/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 9/12 - Loss_Validation\n",
      "Finished Epoch 9/12 - pF1_Validation\n",
      "Train: Loss: 1.2395035475819496, pF1: 0.04656528992831827\n",
      "Valid: Loss: 1.3468088013860138, pF1: 0.043911390331549206\n",
      "Finished Epoch 10/12 - Training\n",
      "Finished Epoch 10/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 10/12 - Loss_Validation\n",
      "Finished Epoch 10/12 - pF1_Validation\n",
      "Train: Loss: 1.224689152307029, pF1: 0.047157988397795614\n",
      "Valid: Loss: 1.3565831218471975, pF1: 0.04368064566337861\n",
      "Finished Epoch 11/12 - Training\n",
      "Finished Epoch 11/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 11/12 - Loss_Validation\n",
      "Finished Epoch 11/12 - pF1_Validation\n",
      "Train: Loss: 1.2092728568588458, pF1: 0.048064637061919754\n",
      "Valid: Loss: 1.340751167091806, pF1: 0.04539726599313516\n",
      "Finished Epoch 12/12 - Training\n",
      "Finished Epoch 12/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 12/12 - Loss_Validation\n",
      "Finished Epoch 12/12 - pF1_Validation\n",
      "Train: Loss: 1.219110650264528, pF1: 0.04818740750689553\n",
      "Valid: Loss: 1.3579813933267622, pF1: 0.04644290000047327\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-05.\n",
      "FOLD 4 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bfee378da649468874d98dc2238ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1/12 - Training\n",
      "Finished Epoch 1/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 1/12 - Loss_Validation\n",
      "Finished Epoch 1/12 - pF1_Validation\n",
      "Train: Loss: 1.3578395096158666, pF1: 0.040664259151875125\n",
      "Valid: Loss: 1.4278455352153945, pF1: 0.04057397056900817\n",
      "Finished Epoch 2/12 - Training\n",
      "Finished Epoch 2/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 2/12 - Loss_Validation\n",
      "Finished Epoch 2/12 - pF1_Validation\n",
      "Train: Loss: 1.3164673452405224, pF1: 0.04212355481572422\n",
      "Valid: Loss: 1.4686968462907675, pF1: 0.03972516556562654\n",
      "Finished Epoch 3/12 - Training\n",
      "Finished Epoch 3/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 3/12 - Loss_Validation\n",
      "Finished Epoch 3/12 - pF1_Validation\n",
      "Train: Loss: 1.3041884576916782, pF1: 0.0431185817167479\n",
      "Valid: Loss: 1.4545195197080238, pF1: 0.040332322585180706\n",
      "Finished Epoch 4/12 - Training\n",
      "Finished Epoch 4/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 4/12 - Loss_Validation\n",
      "Finished Epoch 4/12 - pF1_Validation\n",
      "Train: Loss: 1.2835647004227964, pF1: 0.04407294300414115\n",
      "Valid: Loss: 1.4467882945740327, pF1: 0.040314687989499214\n",
      "Finished Epoch 5/12 - Training\n",
      "Finished Epoch 5/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 5/12 - Loss_Validation\n",
      "Finished Epoch 5/12 - pF1_Validation\n",
      "Train: Loss: 1.2628226820447626, pF1: 0.045249990080963566\n",
      "Valid: Loss: 1.4365174706555532, pF1: 0.04169302593228404\n",
      "Epoch 00005: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Finished Epoch 6/12 - Training\n",
      "Finished Epoch 6/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 6/12 - Loss_Validation\n",
      "Finished Epoch 6/12 - pF1_Validation\n",
      "Train: Loss: 1.2560350045986914, pF1: 0.045349043067721834\n",
      "Valid: Loss: 1.4129087673254377, pF1: 0.04182437051748557\n",
      "Finished Epoch 7/12 - Training\n",
      "Finished Epoch 7/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 7/12 - Loss_Validation\n",
      "Finished Epoch 7/12 - pF1_Validation\n",
      "Train: Loss: 1.2531766312438026, pF1: 0.045338253818327\n",
      "Valid: Loss: 1.4120948163470215, pF1: 0.04186284157674203\n",
      "Finished Epoch 8/12 - Training\n",
      "Finished Epoch 8/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 8/12 - Loss_Validation\n",
      "Finished Epoch 8/12 - pF1_Validation\n",
      "Train: Loss: 1.2477021256152434, pF1: 0.045446864666516706\n",
      "Valid: Loss: 1.4449016111861925, pF1: 0.041885113444649055\n",
      "Finished Epoch 9/12 - Training\n",
      "Finished Epoch 9/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 9/12 - Loss_Validation\n",
      "Finished Epoch 9/12 - pF1_Validation\n",
      "Train: Loss: 1.252266464001433, pF1: 0.045531891049284436\n",
      "Valid: Loss: 1.4381178078238914, pF1: 0.04166970048864479\n",
      "Finished Epoch 10/12 - Training\n",
      "Finished Epoch 10/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 10/12 - Loss_Validation\n",
      "Finished Epoch 10/12 - pF1_Validation\n",
      "Train: Loss: 1.2469003346163423, pF1: 0.04571906855737282\n",
      "Valid: Loss: 1.4353610105004129, pF1: 0.04203609375370519\n",
      "Finished Epoch 11/12 - Training\n",
      "Finished Epoch 11/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 11/12 - Loss_Validation\n",
      "Finished Epoch 11/12 - pF1_Validation\n",
      "Train: Loss: 1.2451487055815478, pF1: 0.04578823992204474\n",
      "Valid: Loss: 1.4321557404009129, pF1: 0.04211195271675232\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Finished Epoch 12/12 - Training\n",
      "Finished Epoch 12/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 12/12 - Loss_Validation\n",
      "Finished Epoch 12/12 - pF1_Validation\n",
      "Train: Loss: 1.2471329204863497, pF1: 0.04575001421788518\n",
      "Valid: Loss: 1.430435059706836, pF1: 0.042074986120352736\n",
      "FOLD 5 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477b8b017d734888b43c8f44586dd944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1/12 - Training\n",
      "Finished Epoch 1/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 1/12 - Loss_Validation\n",
      "Finished Epoch 1/12 - pF1_Validation\n",
      "Train: Loss: 1.3572921342629976, pF1: 0.040769791122574985\n",
      "Valid: Loss: 1.4183310402764215, pF1: 0.03936721107715534\n",
      "Finished Epoch 2/12 - Training\n",
      "Finished Epoch 2/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 2/12 - Loss_Validation\n",
      "Finished Epoch 2/12 - pF1_Validation\n",
      "Train: Loss: 1.3140769763505624, pF1: 0.041805148377793824\n",
      "Valid: Loss: 1.4072618401712842, pF1: 0.039981280683610614\n",
      "Finished Epoch 3/12 - Training\n",
      "Finished Epoch 3/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 3/12 - Loss_Validation\n",
      "Finished Epoch 3/12 - pF1_Validation\n",
      "Train: Loss: 1.2996965348502538, pF1: 0.042967622444965624\n",
      "Valid: Loss: 1.3706101520716796, pF1: 0.04097290697088193\n",
      "Finished Epoch 4/12 - Training\n",
      "Finished Epoch 4/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 4/12 - Loss_Validation\n",
      "Finished Epoch 4/12 - pF1_Validation\n",
      "Train: Loss: 1.285701145459547, pF1: 0.043597320214270915\n",
      "Valid: Loss: 1.3580008229317024, pF1: 0.042303812495372885\n",
      "Finished Epoch 5/12 - Training\n",
      "Finished Epoch 5/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 5/12 - Loss_Validation\n",
      "Finished Epoch 5/12 - pF1_Validation\n",
      "Train: Loss: 1.2754200516430758, pF1: 0.044590773595048726\n",
      "Valid: Loss: 1.3486606684344553, pF1: 0.04266857996593878\n",
      "Finished Epoch 6/12 - Training\n",
      "Finished Epoch 6/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 6/12 - Loss_Validation\n",
      "Finished Epoch 6/12 - pF1_Validation\n",
      "Train: Loss: 1.2614317266018442, pF1: 0.044965848027937655\n",
      "Valid: Loss: 1.3595634535042167, pF1: 0.04395371790136597\n",
      "Finished Epoch 7/12 - Training\n",
      "Finished Epoch 7/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 7/12 - Loss_Validation\n",
      "Finished Epoch 7/12 - pF1_Validation\n",
      "Train: Loss: 1.253301747148719, pF1: 0.04564019121895949\n",
      "Valid: Loss: 1.3333152132598978, pF1: 0.044865171169066985\n",
      "Finished Epoch 8/12 - Training\n",
      "Finished Epoch 8/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 8/12 - Loss_Validation\n",
      "Finished Epoch 8/12 - pF1_Validation\n",
      "Train: Loss: 1.2526702966320313, pF1: 0.04633902217961178\n",
      "Valid: Loss: 1.3446894432717598, pF1: 0.04473665305304379\n",
      "Finished Epoch 9/12 - Training\n",
      "Finished Epoch 9/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 9/12 - Loss_Validation\n",
      "Finished Epoch 9/12 - pF1_Validation\n",
      "Train: Loss: 1.2345565711396753, pF1: 0.047315829218213326\n",
      "Valid: Loss: 1.3538781974399299, pF1: 0.04482255922085796\n",
      "Finished Epoch 10/12 - Training\n",
      "Finished Epoch 10/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 10/12 - Loss_Validation\n",
      "Finished Epoch 10/12 - pF1_Validation\n",
      "Train: Loss: 1.224176849338724, pF1: 0.04720306330876208\n",
      "Valid: Loss: 1.3447933592642958, pF1: 0.04512477265289652\n",
      "Finished Epoch 11/12 - Training\n",
      "Finished Epoch 11/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 11/12 - Loss_Validation\n",
      "Finished Epoch 11/12 - pF1_Validation\n",
      "Train: Loss: 1.2304671588568419, pF1: 0.047772219147732116\n",
      "Valid: Loss: 1.3566748928605465, pF1: 0.045182098181133994\n",
      "Epoch 00011: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Finished Epoch 12/12 - Training\n",
      "Finished Epoch 12/12 - Training_pF1_Evaluation\n",
      "Finished Epoch 12/12 - Loss_Validation\n",
      "Finished Epoch 12/12 - pF1_Validation\n",
      "Train: Loss: 1.2162600002239983, pF1: 0.04865264397417008\n",
      "Valid: Loss: 1.3655912048286862, pF1: 0.04565458408998031\n",
      "CPU times: user 23h 15min 43s, sys: 6h 12min 37s, total: 1d 5h 28min 20s\n",
      "Wall time: 1d 4h 20min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "''' Train 5 models for 12 epochs each with the train/valid-dl created\n",
    "    Each model is starts with random weights\n",
    "    After training the saved metrics from train/valid are written to a df and saved\n",
    "    The model weights are saved as well before they are reset in the next iteration\n",
    "'''\n",
    "\n",
    "num_epochs = 12\n",
    "\n",
    "train_dataloaders = [train_dl_1, train_dl_2, train_dl_3, train_dl_4, train_dl_5]\n",
    "valid_dataloaders = [valid_dl_1, valid_dl_2, valid_dl_3, valid_dl_4, valid_dl_5]\n",
    "\n",
    "df_metrics = pd.DataFrame()  # add metrics for each model after training and save them to csv\n",
    "\n",
    "for fold in range(5):  # for each fold train the model, evaluate it & save weights/metrics\n",
    "    \n",
    "    print(f'FOLD {fold + 1} / 5')\n",
    "    \n",
    "    train_epoch_losses, valid_epoch_losses = [], []\n",
    "    train_epoch_pF1s, valid_epoch_pF1s = [], []\n",
    "    \n",
    "    model_name = f'model_{fold + 1}'\n",
    "    \n",
    "    comb_model.load_state_dict(torch.load(initial_weights))  # load initial weights for each cv-fold\n",
    "    \n",
    "    loss_bce = BCELoss(weight=torch.Tensor(class_weights))  # correct weights assinged in train/val functions\n",
    "    optimizer = Adam(comb_model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "\n",
    "    train_dl = train_dataloaders[fold]  # current loaders for fold\n",
    "    valid_dl = valid_dataloaders[fold]\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        \n",
    "        train_loss, valid_loss = [], []  # metric after each epoch for current model\n",
    "        train_pF1, valid_pF1 = [], []\n",
    "        \n",
    "        # train with all available batches\n",
    "        for index, ((X, add_features), y) in enumerate(train_dl):\n",
    "            X = X.to(device)\n",
    "            add_features = add_features.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_loss = train_batch(model=comb_model, loss=loss_bce, optimizer=optimizer, X=X,\n",
    "                                     add_features=add_features, y=y)\n",
    "            train_loss.append(batch_loss)\n",
    "        print(f'Finished Epoch {epoch + 1}/{num_epochs} - Training')\n",
    "\n",
    "        # calculate pF1-score for all training data\n",
    "        for index, ((X, add_features), y) in enumerate(train_dl):\n",
    "            X = X.to(device)\n",
    "            add_features = add_features.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_pF1 = calculate_pF1(model=comb_model, X=X,add_features=add_features, y=y)\n",
    "            train_pF1.append(batch_pF1)\n",
    "        print(f'Finished Epoch {epoch + 1}/{num_epochs} - Training_pF1_Evaluation')\n",
    "\n",
    "        # calculate loss for all valid data\n",
    "        for index, ((X, add_features), y) in enumerate(valid_dl):\n",
    "            X = X.to(device)\n",
    "            add_features = add_features.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_loss = calculate_val_loss(model=comb_model, loss=loss_bce, X=X, add_features=add_features, y=y)\n",
    "            valid_loss.append(batch_loss)\n",
    "\n",
    "        print(f'Finished Epoch {epoch + 1}/{num_epochs} - Loss_Validation')\n",
    "\n",
    "        # calculate pF1-score for all valid data\n",
    "        for index, ((X, add_features), y) in enumerate(valid_dl):\n",
    "            X = X.to(device)\n",
    "            add_features = add_features.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_pF1 = calculate_pF1(model=comb_model, X=X, add_features=add_features, y=y)\n",
    "            valid_pF1.append(batch_pF1)\n",
    "        print(f'Finished Epoch {epoch + 1}/{num_epochs} - pF1_Validation')\n",
    "\n",
    "        # after training & validating each fold, append the mean values to the lists & continue with the next epoch\n",
    "        train_epoch_loss = np.array(train_loss).mean()\n",
    "        train_epoch_pF1 = np.array(train_pF1).mean()\n",
    "        valid_epoch_loss = np.array(valid_loss).mean()\n",
    "        valid_epoch_pF1 = np.array(valid_pF1).mean()\n",
    "\n",
    "        print(f'Train: Loss: {train_epoch_loss}, pF1: {train_epoch_pF1}')\n",
    "        print(f'Valid: Loss: {valid_epoch_loss}, pF1: {valid_epoch_pF1}')\n",
    "\n",
    "        train_epoch_losses.append(train_epoch_loss)\n",
    "        train_epoch_pF1s.append(train_epoch_pF1)\n",
    "        valid_epoch_losses.append(valid_epoch_loss)\n",
    "        valid_epoch_pF1s.append(valid_epoch_pF1)\n",
    "\n",
    "        scheduler.step(valid_epoch_loss)\n",
    "    \n",
    "    torch.save(comb_model.state_dict(), f'{model_name}.pth')  # save trained weights\n",
    "    \n",
    "    df_metrics[model_name + '_train_loss'] = train_epoch_losses\n",
    "    df_metrics[model_name + '_train_pF1'] = train_epoch_pF1s\n",
    "    df_metrics[model_name + '_valid_loss'] = valid_epoch_losses\n",
    "    df_metrics[model_name + '_valid_pF1'] = valid_epoch_pF1s\n",
    "    \n",
    "    df_metrics.to_csv('Saved_Model_Metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2fb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
